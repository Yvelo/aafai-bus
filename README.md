<div align="center">
  <img src="static/Logo AAF.png" alt="AAF Logo" width="150"/>
</div>

# aafai-bus: An On-Demand Asynchronous Task Processor

> **Note:** This entire project, including the Python/Flask server, the Google Apps Script client, all documentation, and the complete test suite, was generated by **Google's Gemini Code Assistant** in PyCharm, with no lines of code or documentation produced by a human.

## 1. Purpose

**aafai-bus** is a lightweight, on-demand Python server designed to handle long-running, resource-intensive tasks that are delegated from other services. Its primary use case is to act as a "boot-on-demand mini bus" for batch-processing occasional deep internet searches, such as those requiring a full browser via Selenium.

The core goal is to **minimize cloud costs** by keeping the server turned off by default. It is started on-demand by a client, processes a queue of tasks, and then automatically shuts itself down after a period of inactivity.

## 2. Architecture

The system is designed around a client-server model where the client is expected to have the ability to start the server's Virtual Machine (e.g., via a cloud provider's API).

**Typical Flow:**

1.  **Client (e.g., Google Apps Script in a GSheet):** A user triggers an action in a Google Sheet.
2.  **Start VM:** The Apps Script calls the Google Cloud API to start the `aafai-bus` VM instance.
3.  **Submit Task:** Once the VM is running, the script sends a task to the server's `/inbound` endpoint. The server writes the task to a file-based queue and immediately returns a `job_id`.
4.  **Process Task:** The server's background scheduler picks up the task from the queue, executes the requested action, and writes the result to an outbound file.
5.  **Poll for Result:** The Apps Script sets up a time-based trigger to periodically call the server's `/outbound` endpoint with the `job_id`.
6.  **Retrieve Result:** Once the task is complete, the `/outbound` endpoint returns the final JSON result.
7.  **Auto-Shutdown:** After a configurable period of inactivity and once all tasks are processed, the server initiates a full power-off of the VM.

## 3. Security Architecture

The server is secured using a two-pronged approach: a network firewall to block unauthorized requests and a specific `sudo` rule to allow the application to safely shut itself down.

### 3.1. Network Firewall (GCP)

To ensure the server only accepts requests from trusted sources, we configure a firewall rule to allow traffic only from Google's IP ranges.

1.  **Find Google's IP Ranges:** Run the following command to get the current IP ranges for Apps Script:
    ```sh
    nslookup -q=TXT _appsscript.google.com
    ```
2.  **Create a Firewall Rule:** In your GCP project, navigate to **VPC network > Firewall** and create a new **ingress** rule with the following settings:
    - **Name:** `allow-google-apps-script`
    - **Targets:** Apply the rule to your VM using a specific **target tag** (e.g., `aafai-bus-server`).
    - **Source IPv4 ranges:** Enter the IP blocks from step 1.
    - **Protocols and ports:** `tcp:8000` (or your Gunicorn port).
3.  **Tag Your VM:** Add the network tag (e.g., `aafai-bus-server`) to your VM instance in **Compute Engine**.

### 3.2. Auto-Shutdown Permissions

The application runs as the low-privileged `www-data` user. To allow it to power off the entire VM after 30 minutes of idle time, you must grant it a specific, passwordless `sudo` permission.

1.  **Edit the Sudoers File:** On your Debian server, run `sudo visudo`. This is the only safe way to edit this file.
2.  **Add the Rule:** Scroll to the very bottom of the file and add this exact line:
    ```
    www-data ALL=(ALL) NOPASSWD: /sbin/shutdown --poweroff now
    ```
This highly specific rule allows the `www-data` user to do one thing and one thing only: power off the machine.

## 4. Testing Strategy

The project includes a comprehensive test suite using `pytest`. The tests are organized to ensure reliability and maintainability.

To run the tests, execute the following command from the project root:
```sh
pytest
```

### Unit Tests (`tests/unit/`)
Unit tests are focused on testing individual functions and components in isolation. They use **mocks** to simulate the behavior of external dependencies.

### Functional & Integration Tests
These tests verify that different parts of the system work together correctly. A key integration test starts a real, live HTTP server to test the Selenium action against a local, stable web page.

## 5. Features

- **Dynamic Action System:** Add new capabilities by simply dropping a Python file into the `actions/` directory.
- **File-Based Queue:** A simple, durable, and transparent queueing system.
- **Asynchronous Processing:** Uses `APScheduler` with a thread pool to handle multiple tasks concurrently.
- **On-Demand & Auto-Shutdown:** Designed to be started by a client and automatically powers off the VM when idle.
- **Gunicorn & Systemd:** Ready for production deployment using industry-standard tools.
- **Google Scholar Search (`search_google_scholar`):** A new action that performs advanced searches on Google Scholar. It scrapes article details including title, link, snippet, authors (with links to their Scholar profiles, organization, and citation counts where available), publication details, and PDF links. It supports various search parameters (all words, exact phrase, author, publication, date range) and handles pagination up to a configurable maximum number of articles. The author matching logic is designed to be flexible, correctly identifying authors even when names are abbreviated (e.g., a search for "Richard Handler" will correctly match with "R Handler").
- **Semantic Scholar Search (`search_semantic_scholar`):** Performs an advanced search on Semantic Scholar. It scrapes article details including title, link, snippet, authors (with profile URLs and optionally affiliation, total citations, and h-index), publication details, PDF links, and citation counts. It supports various search parameters and can fetch detailed profiles for all or only relevant authors.
- **DocSend Downloader (`docsend_download`):** An action to download documents from DocSend links, handling passcodes if required.
- **Droom Scraper (`scrape_droom`):** An action to scrape detailed information from Droom.org profile pages.

## 6. Setup & Deployment

### Python Environment
1.  Clone the repository.
2.  Create and activate a virtual environment: `python -m venv .venv` & `source .venv/bin/activate`.
3.  Install dependencies: `pip install -r requirements.txt`.
4.  Selenium WebDriver is automatically managed by `selenium-manager`. However, you need to ensure that a compatible browser (like Google Chrome or Chromium) is installed on your system.

### Selenium and Headless Chrome Configuration

The `full_recursive_download` action utilizes Selenium with a headless Chrome browser for web crawling. This section outlines important considerations for its setup and operation.

#### Headless Chrome Dependencies
For the headless Chrome browser to function correctly in a Linux environment (such as a Debian-based VM), you need to install the browser itself and its common dependencies.

```sh
sudo apt-get update
sudo apt-get install -y google-chrome-stable # Or chromium-browser
sudo apt-get install -y fonts-liberation libappindicator3-1 libasound2 libatk-bridge2.0-0 libatk1.0-0 libc6 libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgbm1 libgcc1 libglib2.0-0 libgtk-3-0 libnspr4 libnss3 libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxrandr2 libxrender1 libxss1 libxtst6 lsb-release wget xdg-utils
```

#### Selenium Manager and Driver Cache
Selenium Manager (included with the `selenium` Python package) automatically downloads and manages the correct WebDriver binary (e.g., `chromedriver`) for your installed browser.

-   **`SE_CACHE_PATH`**: The `full_recursive_download` action sets the `SE_CACHE_PATH` environment variable to a job-specific temporary directory (`job_download_dir/selenium_manager_cache`). This ensures that each job uses its own isolated driver cache, preventing conflicts and allowing for proper cleanup.

#### Chrome User Data and `HOME` Environment Variable
Headless Chrome often attempts to write user-specific data (like profiles, caches, and crash dumps) to the user's home directory. When running as a low-privileged user (e.g., `www-data`), this can lead to permission errors if the default `HOME` directory is not writable.

-   **`HOME`**: The `_setup_driver` function in `full_recursive_download.py` explicitly sets the `HOME` environment variable to a temporary directory created for the driver instance. This forces Chrome to store all its user-specific files within this temporary, writable location, resolving potential permission issues. This temporary directory is cleaned up after the driver quits.

### Production Deployment (Linux)
1.  Copy the `aafai-bus.service` file to `/etc/systemd/system/`.
2.  Update paths in the service file to match your deployment directory.
3.  Reload the systemd daemon: `sudo systemctl daemon-reload`.
4.  Enable and start the service: `sudo systemctl enable --now aafai-bus.service`.

## 7. Configuration

Configuration is managed via environment variables, set in the `aafai-bus.service` file for production.

- `APP_ENV`: `production` or `development`.
- `QUEUE_BASE_PATH`: Absolute path for storing queues (e.g., `/var/www/aafai-bus/prod_queues`).

## 8. API Endpoints

### `POST /inbound`
Submits a new task.
- **Body:** `{ "action": "action_name", "params": { ... } }`
- **Response:** `{ "status": "received", "job_id": "..." }`

### `GET /outbound`
Polls for a task result.
- **URL:** `/outbound?job_id=...`
- **Pending Response:** `{ "status": "pending", ... }`
- **Complete Response:** `{ "status": "complete", "result": { ... } }`

## 9. Actions

The following actions are available via the `/inbound` endpoint.

### `search_semantic_scholar`

Performs an advanced search on Semantic Scholar and scrapes the results.

**Input JSON Format:**
```json
{
  "action": "search_semantic_scholar",
  "params": {
    "query": {
      "all_words": "string",
      "exact_phrase": "string",
      "at_least_one": "string",
      "without_words": "string",
      "author": "string",
      "date_range": {
        "start_year": "integer",
        "end_year": "integer"
      }
    },
    "fetch_author_details": "string ('none', 'all', or 'relevant')",
    "max_number_of_articles": "integer"
  }
}
```

### `search_google_scholar`

Performs an advanced search on Google Scholar and scrapes the results.

**Input JSON Format:**
```json
{
  "action": "search_google_scholar",
  "params": {
    "query": {
      "all_words": "string",
      "exact_phrase": "string",
      "at_least_one": "string",
      "without_words": "string",
      "author": "string",
      "publication": "string",
      "date_range": {
        "start_year": "integer",
        "end_year": "integer"
      }
    },
    "fetch_author_details": "string ('none', 'all', or 'relevant')",
    "max_articles": "integer"
  }
}
```

### `full_recursive_download`

Recursively navigates to a URL and extracts all visible text from linked pages within the same domain.

**Input JSON Format:**
```json
{
  "action": "full_recursive_download",
  "params": {
    "url": "string",
    "max_depth": "integer"
  }
}
```

### `docsend_download`

Downloads a document from a DocSend link, handling optional passcodes.

**Input JSON Format:**
```json
{
  "action": "docsend_download",
  "params": {
    "url": "string",
    "passcode": "string (optional)"
  }
}
```

### `scrape_droom`

Scrapes detailed information from a Droom.org profile page.

**Input JSON Format:**
```json
{
  "action": "scrape_droom",
  "params": {
    "url": "string"
  }
}
```

## 10. Google Apps Script Integration

An example client implementation using Google Apps Script can be found here: [examples/google_apps_script/master-bus.gs](examples/google_apps_script/master-bus.gs).

This script can be added to a Google Sheet to:
- Provide a custom menu to start tasks.
- Automatically start the `aafai-bus` VM on Google Cloud.
- Submit tasks and poll for results. It now includes a **batch mode** to efficiently send and retrieve multiple tasks at once.
- Save the final text result to a file in the user's Google Drive.
